
# Paraphrasing-tool

This project uses the Python nltk library to work with human language data. The nltk library, or Natural Language Toolkit, provides tools for building programs that can analyze and understand human language.

The project makes use of three data packages from the nltk library:

  1) Wordnet: A large lexical database of English words. It provides information on word meanings, synonyms, and relationships between words.

  2) Punkt: A pre-trained tokenizer that splits text into sentences and words. Tokenizing text is a necessary step when working with human language data as it breaks the text down into smaller units for analysis.

  3) Averaged Perceptron Tagger: A pre-trained part-of-speech tagger that assigns a grammatical category (such as noun, verb, adjective, etc.) to each word in a text. Part-of-speech tagging is often used in natural language processing tasks such as text classification or sentiment analysis.

Please note that there may be times when the paraphrasing is inaccurate, so itâ€™s important to double-check the output against the input text.



let see an example

Input text

<img width="557" alt="image" src="https://user-images.githubusercontent.com/75522377/233283482-c85366e8-e74f-4f8a-9316-d10119f967b5.png">


Output text :

<img width="558" alt="image" src="https://user-images.githubusercontent.com/75522377/233283860-26efef28-7709-4401-bf7a-ecb4377d47d9.png">


