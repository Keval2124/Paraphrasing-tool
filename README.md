
# Paraphrasing-tool

This project uses the Python nltk library to work with human language data. The nltk library, or Natural Language Toolkit, provides tools for building programs that can analyze and understand human language.

## For Paraphrasing  we be using Natural Language Toolkit

The project makes use of three data packages from the nltk library:

  1) Wordnet: A large lexical database of English words. It provides information on word meanings, synonyms, and relationships between words.

  2) Punkt: A pre-trained tokenizer that splits text into sentences and words. Tokenizing text is a necessary step when working with human language data as it breaks the text down into smaller units for analysis.

  3) Averaged Perceptron Tagger: A pre-trained part-of-speech tagger that assigns a grammatical category (such as noun, verb, adjective, etc.) to each word in a text. Part-of-speech tagging is often used in natural language processing tasks such as text classification or sentiment analysis.

## For grammer correction we be using gingerit

Gingerit is a Python library that facilitates natural language processing tasks such as correcting spelling and grammar errors. It serves as an API wrapper for utilizing grammatical services provided by gingersoftware.com. With Gingerit, users can easily access and use the Ginger correction tool, which offers suggestions for correcting text written in English, Spanish, French, German, Italian, and Portuguese.

Please note that there may be times when the paraphrasing is inaccurate, so itâ€™s important to double-check the output against the input text.


let see an example

Input text

<img width="795" alt="image" src="https://user-images.githubusercontent.com/75522377/233284961-645b97d1-e6aa-47ae-8932-9ba250287923.png">

Output text :

<img width="600" alt="image" src="https://user-images.githubusercontent.com/75522377/235736132-23340322-40de-4a5e-83d7-ba083c37ecbb.png">
